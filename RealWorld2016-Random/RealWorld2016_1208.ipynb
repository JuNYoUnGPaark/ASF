{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1u_FVKXKqB-qKD3y2Tz2VjFX9h7pkoFgI","authorship_tag":"ABX9TyP+c3S6nWoNl9yZgnK8ygqw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DCOlQKBVv77h","executionInfo":{"status":"ok","timestamp":1765278751453,"user_tz":-540,"elapsed":11981,"user":{"displayName":"ë°•ì¤€ì˜","userId":"08318675183777163575"}},"outputId":"983fc551-c5fc-4033-dfd1-343e0820df31"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","í˜„ì¬ ìœ„ì¹˜: /content/drive/MyDrive/Colab Notebooks/ASF/RealWorld2016\n"]}],"source":["import os\n","from google.colab import drive\n","\n","# 1. ë“œë¼ì´ë¸Œ ì—°ê²°\n","drive.mount('/content/drive')\n","\n","# 2. íŒŒì¼ì´ ìˆëŠ” í´ë”ë¡œ ì´ë™ (ì´ë¯¸ì§€ì˜ ê²½ë¡œ ê¸°ì¤€)\n","os.chdir('/content/drive/MyDrive/Colab Notebooks/ASF/RealWorld2016')\n","\n","print(f\"í˜„ì¬ ìœ„ì¹˜: {os.getcwd()}\")"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split  # ì¶”ê°€ë¨\n","from tqdm import tqdm\n","\n","# 1. ì„¤ì •\n","# ==============================================================================\n","# 'subject': ì‚¬ëŒ ê¸°ì¤€ ë¶„ë¦¬ (ì¼ë°˜í™” ì„±ëŠ¥ í‰ê°€ìš© - ì–´ë ¤ì›€)\n","# 'random':  ì „ì²´ ì„ì–´ì„œ ë¶„ë¦¬ (í•™ìŠµ ì˜ ëëŠ”ì§€ í™•ì¸ìš© - ì‰¬ì›€, ì ìˆ˜ ë†’ê²Œ ë‚˜ì˜´)\n","SPLIT_METHOD = 'random'\n","# ==============================================================================\n","\n","# 2. PKL ë¡œë“œ\n","df = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/HAR_data/RealWorld2016/RealWorld2016_Master_Sync.pkl\")\n","\n","WINDOW_SIZE = 100\n","STEP = 50\n","FEATURE_COLS = [c for c in df.columns if 'acc_' in c or 'gyr_' in c]\n","\n","# 3. ë¼ë²¨ ì¸ì½”ë”©\n","le = LabelEncoder()\n","df['label'] = le.fit_transform(df['activity'])\n","print(\"Classes:\", le.classes_)\n","\n","# 4. Windowing í•¨ìˆ˜\n","def create_dataset(df, window_size, step):\n","    Xs, ys = [], []\n","    grouped = df.groupby(['subject_id', 'activity', 'trial'])\n","\n","    for _, group in grouped:\n","        data = group[FEATURE_COLS].values\n","        label = group['label'].values[0]\n","\n","        for i in range(0, len(data) - window_size, step):\n","            window = data[i:i+window_size]\n","            Xs.append(window)\n","            ys.append(label)\n","\n","    return np.array(Xs), np.array(ys)\n","\n","# 5. ë¶„ë¦¬ ë¡œì§ (í•µì‹¬ ë³€ê²½ ë¶€ë¶„)\n","print(f\"ğŸ”„ ë¶„ë¦¬ ë°©ì‹: {SPLIT_METHOD.upper()} Split\")\n","\n","if SPLIT_METHOD == 'subject':\n","    # [ë°©ì‹ A] Subject-wise Split (ê¸°ì¡´ ë°©ì‹)\n","    test_subjects = [6, 11, 12] # ì•„ê¹Œ ì°¾ì€ ìš°ë“±ìƒ ì¡°í•©\n","\n","    train_df = df[~df['subject_id'].isin(test_subjects)].copy()\n","    test_df = df[df['subject_id'].isin(test_subjects)].copy()\n","\n","    print(f\"   Train Subjects: {train_df['subject_id'].unique()}\")\n","    print(f\"   Test Subjects : {test_df['subject_id'].unique()}\")\n","\n","    print(\"â³ ìœˆë„ìš° ìë¥´ê¸° ì‹œì‘...\")\n","    X_train, y_train = create_dataset(train_df, WINDOW_SIZE, STEP)\n","    X_test, y_test = create_dataset(test_df, WINDOW_SIZE, STEP)\n","\n","elif SPLIT_METHOD == 'random':\n","    # [ë°©ì‹ B] Random Split (ì „ì²´ ì„ê¸°)\n","    print(\"â³ ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ìœˆë„ìš°ë¡œ ë³€í™˜ ì¤‘...\")\n","\n","    # 1. ì „ì²´ ë°ì´í„°ë¥¼ í†µì§¸ë¡œ ìë¦„\n","    X_all, y_all = create_dataset(df, WINDOW_SIZE, STEP)\n","\n","    # 2. ë¬´ì‘ìœ„ë¡œ ì„ì–´ì„œ 8:2ë¡œ ë‚˜ëˆ” (stratify=y_allë¡œ í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€)\n","    print(\"ğŸ² ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì–´ì„œ ë‚˜ëˆ„ëŠ” ì¤‘ (Test Size: 20%)...\")\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        X_all, y_all,\n","        test_size=0.2,\n","        random_state=42,\n","        shuffle=True,\n","        stratify=y_all\n","    )\n","\n","print(\"-\" * 30)\n","print(f\"âœ… í•™ìŠµ ë°ì´í„°: {X_train.shape}\")\n","print(f\"âœ… í‰ê°€ ë°ì´í„°: {X_test.shape}\")\n","print(\"-\" * 30)\n","\n","# 6. ì €ì¥ (íŒŒì¼ ì´ë¦„ì€ ê·¸ëŒ€ë¡œ ë‘¬ì•¼ train.pyê°€ ì½ìŠµë‹ˆë‹¤)\n","np.save(\"X_train.npy\", X_train)\n","np.save(\"y_train.npy\", y_train)\n","np.save(\"X_test.npy\", X_test)\n","np.save(\"y_test.npy\", y_test)\n","print(\"ğŸ’¾ ì „ì²˜ë¦¬ ë° ì €ì¥ ì™„ë£Œ!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VfG6bJqQz2Qu","executionInfo":{"status":"ok","timestamp":1765278836437,"user_tz":-540,"elapsed":35573,"user":{"displayName":"ë°•ì¤€ì˜","userId":"08318675183777163575"}},"outputId":"9c3a0cca-d981-4627-97d4-a0ef1b5ddaa8"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Classes: ['climbingdown' 'climbingup' 'jumping' 'lying' 'running' 'sitting'\n"," 'standing' 'walking']\n","ğŸ”„ ë¶„ë¦¬ ë°©ì‹: RANDOM Split\n","â³ ì „ì²´ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ìœˆë„ìš°ë¡œ ë³€í™˜ ì¤‘...\n","ğŸ² ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ì–´ì„œ ë‚˜ëˆ„ëŠ” ì¤‘ (Test Size: 20%)...\n","------------------------------\n","âœ… í•™ìŠµ ë°ì´í„°: (53099, 100, 42)\n","âœ… í‰ê°€ ë°ì´í„°: (13275, 100, 42)\n","------------------------------\n","ğŸ’¾ ì „ì²˜ë¦¬ ë° ì €ì¥ ì™„ë£Œ!\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from tqdm import tqdm\n","\n","# 1. PKL ë¡œë“œ\n","df = pd.read_pickle(\"/content/drive/MyDrive/Colab Notebooks/HAR_data/RealWorld2016/RealWorld2016_Master_Sync.pkl\")\n","\n","WINDOW_SIZE = 100  # 2ì´ˆ (50Hz)\n","STEP = 50          # 50% ê²¹ì¹¨\n","FEATURE_COLS = [c for c in df.columns if 'acc_' in c or 'gyr_' in c] # 42ê°œ ì»¬ëŸ¼\n","\n","# ë¼ë²¨ ì¸ì½”ë”©\n","le = LabelEncoder()\n","df['label'] = le.fit_transform(df['activity'])\n","print(\"Classes:\", le.classes_)\n","\n","# Windowing í•¨ìˆ˜ (ìˆ˜ì •ë¨: Instance Norm ì¶”ê°€)\n","def create_dataset(df, window_size, step):\n","    Xs, ys = [], []\n","    grouped = df.groupby(['subject_id', 'activity', 'trial'])\n","\n","    for _, group in grouped:\n","        data = group[FEATURE_COLS].values\n","        label = group['label'].values[0]\n","\n","        # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°\n","        for i in range(0, len(data) - window_size, step):\n","            window = data[i:i+window_size]\n","\n","            Xs.append(window)\n","            ys.append(label)\n","\n","    return np.array(Xs), np.array(ys)\n","\n","# Train / Test ë¶„ë¦¬\n","test_subjects = [6, 11, 12]\n","test_df = df[df['subject_id'].isin(test_subjects)].copy()\n","train_df = df[~df['subject_id'].isin(test_subjects)].copy() # ~ëŠ” ë°˜ëŒ€(NOT)ë¥¼ ì˜ë¯¸\n","print(f\"Train Subjects: {train_df['subject_id'].unique()}\")\n","print(f\"Test Subjects : {test_df['subject_id'].unique()}\")\n","\n","print(\"â³ ìœˆë„ìš° ìë¥´ê¸° ì‹œì‘... (ì¡°ê¸ˆ ê±¸ë¦¼)\")\n","X_train, y_train = create_dataset(train_df, WINDOW_SIZE, STEP)\n","X_test, y_test = create_dataset(test_df, WINDOW_SIZE, STEP)\n","\n","print(f\"âœ… í•™ìŠµ ë°ì´í„°: {X_train.shape}\")\n","print(f\"âœ… í‰ê°€ ë°ì´í„°: {X_test.shape}\")\n","\n","# ì €ì¥\n","np.save(\"X_train.npy\", X_train)\n","np.save(\"y_train.npy\", y_train)\n","np.save(\"X_test.npy\", X_test)\n","np.save(\"y_test.npy\", y_test)\n","print(\"ğŸ’¾ ì „ì²˜ë¦¬ ë° ì €ì¥ ì™„ë£Œ!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5MpO2ipyIHP","executionInfo":{"status":"ok","timestamp":1765203244192,"user_tz":-540,"elapsed":37203,"user":{"displayName":"ë°•ì¤€ì˜","userId":"08318675183777163575"}},"outputId":"e44f616f-f337-4636-a66d-cc40bc73f909"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Classes: ['climbingdown' 'climbingup' 'jumping' 'lying' 'running' 'sitting'\n"," 'standing' 'walking']\n","Train Subjects: [ 1  2  3  4  5  7  8  9 10 13 14 15]\n","Test Subjects : [ 6 11 12]\n","â³ ìœˆë„ìš° ìë¥´ê¸° ì‹œì‘... (ì¡°ê¸ˆ ê±¸ë¦¼)\n","âœ… í•™ìŠµ ë°ì´í„°: (53459, 100, 42)\n","âœ… í‰ê°€ ë°ì´í„°: (12915, 100, 42)\n","ğŸ’¾ ì „ì²˜ë¦¬ ë° ì €ì¥ ì™„ë£Œ!\n"]}]},{"cell_type":"code","source":["!pip install fvcore"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dCO_GxHIw8M3","executionInfo":{"status":"ok","timestamp":1765278865967,"user_tz":-540,"elapsed":20039,"user":{"displayName":"ë°•ì¤€ì˜","userId":"08318675183777163575"}},"outputId":"844fbf5a-db02-4428-9815-4907c11165fd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fvcore\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m755.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fvcore) (2.0.2)\n","Collecting yacs>=0.1.6 (from fvcore)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from fvcore) (6.0.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from fvcore) (4.67.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore) (3.2.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from fvcore) (11.3.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore) (0.9.0)\n","Collecting iopath>=0.1.7 (from fvcore)\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from iopath>=0.1.7->fvcore) (4.15.0)\n","Collecting portalocker (from iopath>=0.1.7->fvcore)\n","  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=13e8797e90a06c415853ca29f7a3a7532b4ecba95c796df84d206b2f4cf1ac17\n","  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=aa493ddbcea480963791db15c538d525b95b0338856643e9640648d08666f083\n","  Stored in directory: /root/.cache/pip/wheels/7c/96/04/4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n","Successfully built fvcore iopath\n","Installing collected packages: yacs, portalocker, iopath, fvcore\n","Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.2.0 yacs-0.1.8\n"]}]},{"cell_type":"code","source":["!python train.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbjscBqgw9Cp","executionInfo":{"status":"ok","timestamp":1765279816220,"user_tz":-540,"elapsed":950251,"user":{"displayName":"ë°•ì¤€ì˜","userId":"08318675183777163575"}},"outputId":"463e3220-8a77-47c4-8183-19f24f42348f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[01/50] Train Loss: 0.853 | F1: 0.7980  |  Test F1: 0.8650 (Best: 0.8650) Saved Best Model\n","[02/50] Train Loss: 0.551 | F1: 0.9340  |  Test F1: 0.9393 (Best: 0.9393) Saved Best Model\n","[03/50] Train Loss: 0.495 | F1: 0.9513  |  Test F1: 0.9525 (Best: 0.9525) Saved Best Model\n","[04/50] Train Loss: 0.469 | F1: 0.9569  |  Test F1: 0.9455 (Best: 0.9525) \n","[05/50] Train Loss: 0.450 | F1: 0.9614  |  Test F1: 0.9639 (Best: 0.9639) Saved Best Model\n","[06/50] Train Loss: 0.437 | F1: 0.9635  |  Test F1: 0.9583 (Best: 0.9639) \n","[07/50] Train Loss: 0.426 | F1: 0.9672  |  Test F1: 0.9704 (Best: 0.9704) Saved Best Model\n","[08/50] Train Loss: 0.419 | F1: 0.9681  |  Test F1: 0.9736 (Best: 0.9736) Saved Best Model\n","[09/50] Train Loss: 0.408 | F1: 0.9712  |  Test F1: 0.9679 (Best: 0.9736) \n","[10/50] Train Loss: 0.402 | F1: 0.9716  |  Test F1: 0.9740 (Best: 0.9740) Saved Best Model\n","[11/50] Train Loss: 0.397 | F1: 0.9732  |  Test F1: 0.9693 (Best: 0.9740) \n","[12/50] Train Loss: 0.393 | F1: 0.9749  |  Test F1: 0.9745 (Best: 0.9745) Saved Best Model\n","[13/50] Train Loss: 0.391 | F1: 0.9738  |  Test F1: 0.9721 (Best: 0.9745) \n","[14/50] Train Loss: 0.383 | F1: 0.9765  |  Test F1: 0.9702 (Best: 0.9745) \n","[15/50] Train Loss: 0.380 | F1: 0.9772  |  Test F1: 0.9736 (Best: 0.9745) \n","[16/50] Train Loss: 0.376 | F1: 0.9774  |  Test F1: 0.9754 (Best: 0.9754) Saved Best Model\n","[17/50] Train Loss: 0.372 | F1: 0.9797  |  Test F1: 0.9783 (Best: 0.9783) Saved Best Model\n","[18/50] Train Loss: 0.369 | F1: 0.9801  |  Test F1: 0.9763 (Best: 0.9783) \n","[19/50] Train Loss: 0.365 | F1: 0.9812  |  Test F1: 0.9764 (Best: 0.9783) \n","[20/50] Train Loss: 0.363 | F1: 0.9814  |  Test F1: 0.9722 (Best: 0.9783) \n","[21/50] Train Loss: 0.361 | F1: 0.9824  |  Test F1: 0.9761 (Best: 0.9783) \n","[22/50] Train Loss: 0.357 | F1: 0.9833  |  Test F1: 0.9747 (Best: 0.9783) \n","[23/50] Train Loss: 0.357 | F1: 0.9830  |  Test F1: 0.9805 (Best: 0.9805) Saved Best Model\n","[24/50] Train Loss: 0.352 | F1: 0.9846  |  Test F1: 0.9815 (Best: 0.9815) Saved Best Model\n","[25/50] Train Loss: 0.349 | F1: 0.9847  |  Test F1: 0.9802 (Best: 0.9815) \n","[26/50] Train Loss: 0.345 | F1: 0.9857  |  Test F1: 0.9822 (Best: 0.9822) Saved Best Model\n","[27/50] Train Loss: 0.343 | F1: 0.9866  |  Test F1: 0.9807 (Best: 0.9822) \n","[28/50] Train Loss: 0.341 | F1: 0.9864  |  Test F1: 0.9819 (Best: 0.9822) \n","[29/50] Train Loss: 0.337 | F1: 0.9876  |  Test F1: 0.9839 (Best: 0.9839) Saved Best Model\n","[30/50] Train Loss: 0.333 | F1: 0.9891  |  Test F1: 0.9836 (Best: 0.9839) \n","[31/50] Train Loss: 0.332 | F1: 0.9892  |  Test F1: 0.9828 (Best: 0.9839) \n","[32/50] Train Loss: 0.328 | F1: 0.9903  |  Test F1: 0.9838 (Best: 0.9839) \n","[33/50] Train Loss: 0.326 | F1: 0.9909  |  Test F1: 0.9851 (Best: 0.9851) Saved Best Model\n","[34/50] Train Loss: 0.325 | F1: 0.9915  |  Test F1: 0.9851 (Best: 0.9851) Saved Best Model\n","[35/50] Train Loss: 0.324 | F1: 0.9914  |  Test F1: 0.9859 (Best: 0.9859) Saved Best Model\n","[36/50] Train Loss: 0.320 | F1: 0.9929  |  Test F1: 0.9869 (Best: 0.9869) Saved Best Model\n","[37/50] Train Loss: 0.318 | F1: 0.9934  |  Test F1: 0.9873 (Best: 0.9873) Saved Best Model\n","[38/50] Train Loss: 0.318 | F1: 0.9934  |  Test F1: 0.9860 (Best: 0.9873) \n","[39/50] Train Loss: 0.316 | F1: 0.9936  |  Test F1: 0.9867 (Best: 0.9873) \n","[40/50] Train Loss: 0.315 | F1: 0.9939  |  Test F1: 0.9866 (Best: 0.9873) \n","[41/50] Train Loss: 0.313 | F1: 0.9946  |  Test F1: 0.9876 (Best: 0.9876) Saved Best Model\n","[42/50] Train Loss: 0.311 | F1: 0.9949  |  Test F1: 0.9883 (Best: 0.9883) Saved Best Model\n","[43/50] Train Loss: 0.312 | F1: 0.9950  |  Test F1: 0.9885 (Best: 0.9885) Saved Best Model\n","[44/50] Train Loss: 0.311 | F1: 0.9951  |  Test F1: 0.9888 (Best: 0.9888) Saved Best Model\n","[45/50] Train Loss: 0.310 | F1: 0.9956  |  Test F1: 0.9891 (Best: 0.9891) Saved Best Model\n","[46/50] Train Loss: 0.310 | F1: 0.9956  |  Test F1: 0.9889 (Best: 0.9891) \n","[47/50] Train Loss: 0.309 | F1: 0.9957  |  Test F1: 0.9888 (Best: 0.9891) \n","[48/50] Train Loss: 0.310 | F1: 0.9957  |  Test F1: 0.9889 (Best: 0.9891) \n","[49/50] Train Loss: 0.308 | F1: 0.9961  |  Test F1: 0.9890 (Best: 0.9891) \n","[50/50] Train Loss: 0.307 | F1: 0.9962  |  Test F1: 0.9891 (Best: 0.9891) \n"]}]},{"cell_type":"code","source":["!python visualize.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ykXaTdNw98s","executionInfo":{"status":"ok","timestamp":1765279920704,"user_tz":-540,"elapsed":100917,"user":{"displayName":"ë°•ì¤€ì˜","userId":"08318675183777163575"}},"outputId":"25acab39-8608-4db5-8a86-1d310ed89016"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["--------------------------------------------------------------------------------\n","Running Visualization...\n","Loading weights from: /content/drive/MyDrive/Colab Notebooks/ASF/RealWorld2016/RealWorld2016_ASF.pth\n","--------------------------------------------------------------------------------\n","âœ… Model weights loaded successfully!\n","--------------------------------------------------------------------------------\n","Evaluating Model Efficiency...\n","1. Parameters       : 0.1015 M\n","2. FLOPs / sample   : 5.825 M\n","3. Infer time       : 2.12 ms/sample\n","--------------------------------------------------------------------------------\n","Extracting features and predictions...\n","Generating Confusion Matrix...\n","\n","================================================================================\n","Classification Report\n","================================================================================\n","              precision    recall  f1-score   support\n","\n","climbingdown     0.9946    0.9867    0.9907      1507\n","  climbingup     0.9838    0.9866    0.9852      1785\n","     jumping     0.9962    0.9630    0.9793       270\n","       lying     0.9953    0.9927    0.9940      1924\n","     running     0.9861    0.9912    0.9886      2151\n","     sitting     0.9881    0.9969    0.9925      1921\n","    standing     0.9961    0.9972    0.9966      1778\n","     walking     0.9886    0.9840    0.9863      1939\n","\n","    accuracy                         0.9903     13275\n","   macro avg     0.9911    0.9873    0.9891     13275\n","weighted avg     0.9903    0.9903    0.9903     13275\n","\n","Figure(1800x1800)\n","Generating Feature t-SNE...\n","\n","Running t-SNE on 2000 points (Perplexity=30)...\n","Figure(800x800)\n","Generating Raw Data t-SNE...\n","\n","Running Raw Data t-SNE on 2000 points...\n","Figure(800x800)\n","\n","Visualization Complete!\n"]}]},{"cell_type":"markdown","source":["*5Fold & LOSO íƒìƒ‰*\n","\n"],"metadata":{"id":"5VfPmfYrPd16"}},{"cell_type":"code","source":["import os\n","import copy\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import GroupKFold\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score\n","from tqdm import tqdm\n","\n","# ê¸°ì¡´ì— ì‘ì„±í•˜ì‹  ëª¨ë¸ íŒŒì¼ë“¤ ë¶ˆëŸ¬ì˜¤ê¸°\n","from model_utils import set_seed, seed_worker, ASFDCLClassifier\n","\n","# ------------------------------------------------------------------------------\n","# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ (ì „ì²´ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¼)\n","# ------------------------------------------------------------------------------\n","DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/HAR_data/RealWorld2016/RealWorld2016_Master_Sync.pkl\"\n","WINDOW_SIZE = 100\n","STEP = 50\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def load_and_preprocess_all():\n","    print(\"â³ ì „ì²´ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘...\")\n","    df = pd.read_pickle(DATA_PATH)\n","\n","    # ì»¬ëŸ¼ ì„ íƒ\n","    feature_cols = [c for c in df.columns if 'acc_' in c or 'gyr_' in c]\n","\n","    # ë¼ë²¨ ì¸ì½”ë”©\n","    le = LabelEncoder()\n","    df['label'] = le.fit_transform(df['activity'])\n","\n","    # ìœˆë„ìš° ìë¥´ê¸° (ì •ê·œí™” ì—†ì´ Rawë¡œ)\n","    Xs, ys, groups = [], [], []\n","\n","    # ê·¸ë£¹í™” (ì‚¬ëŒ ë‹¨ìœ„ë¡œ ìª¼ê°œê¸° ìœ„í•´)\n","    grouped = df.groupby(['subject_id', 'activity', 'trial'])\n","\n","    for _, group in grouped:\n","        data = group[feature_cols].values\n","        label = group['label'].values[0]\n","        subj_id = group['subject_id'].values[0]\n","\n","        for i in range(0, len(data) - WINDOW_SIZE, STEP):\n","            window = data[i:i+WINDOW_SIZE]\n","            Xs.append(window)\n","            ys.append(label)\n","            groups.append(subj_id) # ë‚˜ì¤‘ì— ì‚¬ëŒ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ìœ„í•´ ì €ì¥\n","\n","    Xs = np.array(Xs).astype(np.float32)\n","    ys = np.array(ys).astype(np.longlong)\n","    groups = np.array(groups)\n","\n","\n","    print(f\"âœ… ì „ì²´ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {Xs.shape}\")\n","    return Xs, ys, groups\n","\n","# ------------------------------------------------------------------------------\n","# 2. ê°„ë‹¨í•œ Dataset í´ë˜ìŠ¤\n","# ------------------------------------------------------------------------------\n","class SimpleDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","    def __len__(self):\n","        return len(self.y)\n","    def __getitem__(self, idx):\n","        return torch.from_numpy(self.X[idx]), torch.tensor(self.y[idx])\n","\n","# ------------------------------------------------------------------------------\n","# 3. í•™ìŠµ í•¨ìˆ˜ (1 Epochë§Œ ë¹ ë¥´ê²Œ ëŒë ¤ì„œ ê°„ ë³´ê¸° or Full í•™ìŠµ)\n","# ------------------------------------------------------------------------------\n","def train_and_evaluate(train_idx, test_idx, X, y, fold_num, epochs=10):\n","    # ë°ì´í„° ë¶„í• \n","    X_train, X_test = X[train_idx], X[test_idx]\n","    y_train, y_test = y[train_idx], y[test_idx]\n","\n","    # ë°ì´í„°ì…‹ & ë¡œë”\n","    train_ds = SimpleDataset(X_train, y_train)\n","    test_ds = SimpleDataset(X_test, y_test)\n","\n","    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True, num_workers=0)\n","    test_loader = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=0)\n","\n","    # ëª¨ë¸ ì´ˆê¸°í™” (ë§¤ í´ë“œë§ˆë‹¤ ìƒˆë¡œ ë§Œë“¤ì–´ì•¼ í•¨)\n","    model = ASFDCLClassifier(\n","        input_channels=42, latent_dim=64, hidden_dim=64,\n","        num_classes=8, num_heads=4, projection_dim=128\n","    ).to(DEVICE)\n","\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    # í•™ìŠµ ë£¨í”„\n","    best_f1 = 0.0\n","\n","    print(f\"\\nğŸš€ Fold {fold_num} í•™ìŠµ ì‹œì‘ (Epochs: {epochs})...\")\n","    for epoch in range(epochs):\n","        model.train()\n","        for bx, by in train_loader:\n","            bx, by = bx.to(DEVICE), by.to(DEVICE)\n","            optimizer.zero_grad()\n","            logits = model(bx) # ë‹¨ìˆœ ë¶„ë¥˜ ë¡œìŠ¤ë§Œ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥´ê²Œ íƒìƒ‰ (í•„ìš”ì‹œ ASF ë¡œìŠ¤ ì‚¬ìš©)\n","            loss = criterion(logits, by)\n","            loss.backward()\n","            optimizer.step()\n","\n","        # í‰ê°€\n","        model.eval()\n","        all_preds, all_labels = [], []\n","        with torch.no_grad():\n","            for bx, by in test_loader:\n","                bx, by = bx.to(DEVICE), by.to(DEVICE)\n","                logits = model(bx)\n","                preds = torch.argmax(logits, dim=1)\n","                all_preds.extend(preds.cpu().numpy())\n","                all_labels.extend(by.cpu().numpy())\n","\n","        f1 = f1_score(all_labels, all_preds, average='macro')\n","        if f1 > best_f1:\n","            best_f1 = f1\n","\n","    return best_f1\n","\n","# ------------------------------------------------------------------------------\n","# 4. ë©”ì¸: K-Fold ì„œì¹˜\n","# ------------------------------------------------------------------------------\n","def main():\n","    set_seed(42)\n","\n","    # 1. ë°ì´í„° ë¡œë“œ\n","    X, y, groups = load_and_preprocess_all()\n","\n","    # 2. Group K-Fold ì„¤ì • (5ë“±ë¶„ -> 15ëª…ì´ë‹ˆê¹Œ ê·¸ë£¹ë‹¹ 3ëª…ì”© í…ŒìŠ¤íŠ¸)\n","    gkf = GroupKFold(n_splits=5)\n","\n","    results = []\n","\n","    # 3. í´ë“œë³„ ìˆœíšŒ\n","    for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups)):\n","        # í˜„ì¬ í…ŒìŠ¤íŠ¸ì— ì“°ì´ëŠ” ì‚¬ëŒ ID í™•ì¸\n","        test_subjects = np.unique(groups[test_idx])\n","        train_subjects = np.unique(groups[train_idx])\n","\n","        print(\"=\"*60)\n","        print(f\"ğŸ“Œ Fold {fold+1}/5\")\n","        print(f\"   â–¶ Test Subjects : {test_subjects}\") # ëˆ„êµ¬ë¥¼ í…ŒìŠ¤íŠ¸í•˜ëŠ”ê°€?\n","        print(f\"   â–¶ Train Subjects: {len(train_subjects)}ëª…\")\n","\n","        # í•™ìŠµ ìˆ˜í–‰ (ì—¬ê¸°ì„œ Epochì„ ì¡°ì ˆí•˜ì„¸ìš”. ì°¾ê¸°ìš©ì´ë‹ˆ 5~10 ì •ë„ë¡œ ì§§ê²Œ)\n","        score = train_and_evaluate(train_idx, test_idx, X, y, fold_num=fold+1, epochs=10)\n","\n","        print(f\"   ğŸ† Best F1 Score: {score:.4f}\")\n","        results.append({\n","            \"fold\": fold+1,\n","            \"test_subjects\": test_subjects.tolist(),\n","            \"f1_score\": score\n","        })\n","\n","    # 4. ê²°ê³¼ ì¢…í•©\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"ğŸ“Š ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸ (ì ìˆ˜ ë†’ì€ ìˆœ)\")\n","    print(\"=\"*60)\n","\n","    # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬\n","    sorted_results = sorted(results, key=lambda x: x['f1_score'], reverse=True)\n","\n","    for rank, res in enumerate(sorted_results):\n","        print(f\"{rank+1}ìœ„ | Test Subjects: {res['test_subjects']} | F1: {res['f1_score']:.4f}\")\n","\n","    print(f\"\\nğŸ’¡ ì „ì²´ í‰ê·  F1 Score: {np.mean([r['f1_score'] for r in results]):.4f}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-DsQrI7pLA1Q","executionInfo":{"status":"ok","timestamp":1765201322359,"user_tz":-540,"elapsed":378728,"user":{"displayName":"ë°•ì¤€ì˜","userId":"08318675183777163575"}},"outputId":"01edf651-49d1-4960-e0fe-c0546344ad6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["â³ ì „ì²´ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘...\n","âœ… ì „ì²´ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: (66374, 100, 42)\n","============================================================\n","ğŸ“Œ Fold 1/5\n","   â–¶ Test Subjects : [ 2  5 13]\n","   â–¶ Train Subjects: 12ëª…\n","\n","ğŸš€ Fold 1 í•™ìŠµ ì‹œì‘ (Epochs: 10)...\n","   ğŸ† Best F1 Score: 0.7223\n","============================================================\n","ğŸ“Œ Fold 2/5\n","   â–¶ Test Subjects : [ 8 10 11]\n","   â–¶ Train Subjects: 12ëª…\n","\n","ğŸš€ Fold 2 í•™ìŠµ ì‹œì‘ (Epochs: 10)...\n","   ğŸ† Best F1 Score: 0.6687\n","============================================================\n","ğŸ“Œ Fold 3/5\n","   â–¶ Test Subjects : [1 6 7]\n","   â–¶ Train Subjects: 12ëª…\n","\n","ğŸš€ Fold 3 í•™ìŠµ ì‹œì‘ (Epochs: 10)...\n","   ğŸ† Best F1 Score: 0.7080\n","============================================================\n","ğŸ“Œ Fold 4/5\n","   â–¶ Test Subjects : [ 3 12 15]\n","   â–¶ Train Subjects: 12ëª…\n","\n","ğŸš€ Fold 4 í•™ìŠµ ì‹œì‘ (Epochs: 10)...\n","   ğŸ† Best F1 Score: 0.6792\n","============================================================\n","ğŸ“Œ Fold 5/5\n","   â–¶ Test Subjects : [ 4  9 14]\n","   â–¶ Train Subjects: 12ëª…\n","\n","ğŸš€ Fold 5 í•™ìŠµ ì‹œì‘ (Epochs: 10)...\n","   ğŸ† Best F1 Score: 0.7909\n","\n","============================================================\n","ğŸ“Š ìµœì¢… ê²°ê³¼ ë¦¬í¬íŠ¸ (ì ìˆ˜ ë†’ì€ ìˆœ)\n","============================================================\n","1ìœ„ | Test Subjects: [4, 9, 14] | F1: 0.7909\n","2ìœ„ | Test Subjects: [2, 5, 13] | F1: 0.7223\n","3ìœ„ | Test Subjects: [1, 6, 7] | F1: 0.7080\n","4ìœ„ | Test Subjects: [3, 12, 15] | F1: 0.6792\n","5ìœ„ | Test Subjects: [8, 10, 11] | F1: 0.6687\n","\n","ğŸ’¡ ì „ì²´ í‰ê·  F1 Score: 0.7138\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import LeaveOneGroupOut # ì´ í•¨ìˆ˜ê°€ í•µì‹¬ì…ë‹ˆë‹¤\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import f1_score\n","from model_utils import set_seed, ASFDCLClassifier  # ê¸°ì¡´ íŒŒì¼ í™œìš©\n","\n","# ì„¤ì •\n","DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/HAR_data/RealWorld2016/RealWorld2016_Master_Sync.pkl\"\n","WINDOW_SIZE = 100\n","STEP = 50\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","def load_and_preprocess_all():\n","    print(\"â³ ì „ì²´ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘...\")\n","    df = pd.read_pickle(DATA_PATH)\n","\n","    # ì»¬ëŸ¼ ì„ íƒ\n","    feature_cols = [c for c in df.columns if 'acc_' in c or 'gyr_' in c]\n","\n","    # ë¼ë²¨ ì¸ì½”ë”©\n","    le = LabelEncoder()\n","    df['label'] = le.fit_transform(df['activity'])\n","\n","    # ìœˆë„ìš° ìë¥´ê¸° (ì •ê·œí™” ì—†ì´ Rawë¡œ)\n","    Xs, ys, groups = [], [], []\n","\n","    # ê·¸ë£¹í™” (ì‚¬ëŒ ë‹¨ìœ„ë¡œ ìª¼ê°œê¸° ìœ„í•´)\n","    grouped = df.groupby(['subject_id', 'activity', 'trial'])\n","\n","    for _, group in grouped:\n","        data = group[feature_cols].values\n","        label = group['label'].values[0]\n","        subj_id = group['subject_id'].values[0]\n","\n","        for i in range(0, len(data) - WINDOW_SIZE, STEP):\n","            window = data[i:i+WINDOW_SIZE]\n","            Xs.append(window)\n","            ys.append(label)\n","            groups.append(subj_id) # ë‚˜ì¤‘ì— ì‚¬ëŒ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ìœ„í•´ ì €ì¥\n","\n","    Xs = np.array(Xs).astype(np.float32)\n","    ys = np.array(ys).astype(np.longlong)\n","    groups = np.array(groups)\n","\n","\n","    print(f\"âœ… ì „ì²´ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {Xs.shape}\")\n","    return Xs, ys, groups\n","\n","# ------------------------------------------------------------------------------\n","# 2. ê°„ë‹¨í•œ Dataset í´ë˜ìŠ¤\n","# ------------------------------------------------------------------------------\n","class SimpleDataset(Dataset):\n","    def __init__(self, X, y):\n","        self.X = X\n","        self.y = y\n","    def __len__(self):\n","        return len(self.y)\n","    def __getitem__(self, idx):\n","        return torch.from_numpy(self.X[idx]), torch.tensor(self.y[idx])\n","\n","def train_and_evaluate(train_idx, test_idx, X, y, subject_id, epochs=10):\n","    # ë°ì´í„° ë¶„í• \n","    X_train, X_test = X[train_idx], X[test_idx]\n","    y_train, y_test = y[train_idx], y[test_idx]\n","\n","    # Dataset & Loader\n","    train_ds = SimpleDataset(X_train, y_train)\n","    test_ds = SimpleDataset(X_test, y_test)\n","    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n","    test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n","\n","    # ëª¨ë¸ ì´ˆê¸°í™”\n","    model = ASFDCLClassifier(\n","        input_channels=42, latent_dim=64, hidden_dim=64,\n","        num_classes=8, num_heads=4, projection_dim=128\n","    ).to(DEVICE)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    best_f1 = 0.0\n","\n","    # ì§§ì€ í•™ìŠµ\n","    for epoch in range(epochs):\n","        model.train()\n","        for bx, by in train_loader:\n","            bx, by = bx.to(DEVICE), by.to(DEVICE)\n","            optimizer.zero_grad()\n","            output = model(bx)\n","            loss = criterion(output, by)\n","            loss.backward()\n","            optimizer.step()\n","\n","        # í‰ê°€\n","        model.eval()\n","        preds, labels = [], []\n","        with torch.no_grad():\n","            for bx, by in test_loader:\n","                bx, by = bx.to(DEVICE), by.to(DEVICE)\n","                output = model(bx)\n","                preds.extend(torch.argmax(output, dim=1).cpu().numpy())\n","                labels.extend(by.cpu().numpy())\n","\n","        current_f1 = f1_score(labels, preds, average='macro')\n","        if current_f1 > best_f1:\n","            best_f1 = current_f1\n","\n","    return best_f1\n","\n","def main():\n","    set_seed(42)\n","    X, y, groups = load_and_preprocess_all() # ì´ì „ ì½”ë“œì˜ í•¨ìˆ˜ ì‚¬ìš©\n","\n","    # ğŸ”¥ í•µì‹¬ ë³€ê²½: LeaveOneGroupOut (ì´ 15ë²ˆ ìˆ˜í–‰)\n","    logo = LeaveOneGroupOut()\n","\n","    results = []\n","\n","    print(f\"\\nğŸš€ Leave-One-Subject-Out (ì´ 15íšŒ) ì‹œì‘...\\n\")\n","\n","    for fold, (train_idx, test_idx) in enumerate(logo.split(X, y, groups)):\n","        test_subject = np.unique(groups[test_idx])[0] # í˜„ì¬ í…ŒìŠ¤íŠ¸í•˜ëŠ” 1ëª…\n","\n","        print(f\"[{fold+1}/15] Test Subject: {test_subject}ë²ˆ í‰ê°€ ì¤‘...\")\n","\n","        score = train_and_evaluate(train_idx, test_idx, X, y, test_subject, epochs=5) # 5 Epochë§Œ ë¹ ë¥´ê²Œ\n","\n","        print(f\"   -> Best F1: {score:.4f}\")\n","        results.append({\"subject\": test_subject, \"f1\": score})\n","\n","    # ê²°ê³¼ ë¦¬í¬íŠ¸\n","    print(\"\\n\" + \"=\"*40)\n","    print(\"ğŸ“Š í”¼í—˜ìë³„ ë‚œì´ë„ ë¦¬í¬íŠ¸ (F1 ë‚®ì€ ìˆœ = ì–´ë ¤ìš´ ì‚¬ëŒ)\")\n","    print(\"=\"*40)\n","\n","    # ì ìˆ˜ê°€ ë‚®ì€ ìˆœ(ì–´ë ¤ìš´ ì‚¬ëŒ)ìœ¼ë¡œ ì •ë ¬\n","    sorted_res = sorted(results, key=lambda x: x['f1'])\n","\n","    for res in sorted_res:\n","        print(f\"Subject {res['subject']}: {res['f1']:.4f}\")\n","\n","    print(f\"\\nâ­ ì „ì²´ í‰ê·  F1: {np.mean([r['f1'] for r in results]):.4f}\")\n","\n","if __name__ == \"__main__\":\n","    main() # ì‹¤í–‰ ì „ì— ì´ì „ ì½”ë“œì˜ load_and_preprocess_all, SimpleDataset ì •ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TXAExge4Mt6_","executionInfo":{"status":"ok","timestamp":1765201956162,"user_tz":-540,"elapsed":581126,"user":{"displayName":"ë°•ì¤€ì˜","userId":"08318675183777163575"}},"outputId":"ee615e59-2f11-4dd7-82f0-c1597e2250ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["â³ ì „ì²´ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì¤‘...\n","âœ… ì „ì²´ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: (66374, 100, 42)\n","\n","ğŸš€ Leave-One-Subject-Out (ì´ 15íšŒ) ì‹œì‘...\n","\n","[1/15] Test Subject: 1ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.7379\n","[2/15] Test Subject: 2ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.6829\n","[3/15] Test Subject: 3ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.4576\n","[4/15] Test Subject: 4ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.7428\n","[5/15] Test Subject: 5ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.7914\n","[6/15] Test Subject: 6ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.8484\n","[7/15] Test Subject: 7ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.7624\n","[8/15] Test Subject: 8ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.4430\n","[9/15] Test Subject: 9ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.8313\n","[10/15] Test Subject: 10ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.7666\n","[11/15] Test Subject: 11ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.8542\n","[12/15] Test Subject: 12ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.9131\n","[13/15] Test Subject: 13ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.7589\n","[14/15] Test Subject: 14ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.7931\n","[15/15] Test Subject: 15ë²ˆ í‰ê°€ ì¤‘...\n","   -> Best F1: 0.7184\n","\n","========================================\n","ğŸ“Š í”¼í—˜ìë³„ ë‚œì´ë„ ë¦¬í¬íŠ¸ (F1 ë‚®ì€ ìˆœ = ì–´ë ¤ìš´ ì‚¬ëŒ)\n","========================================\n","Subject 8: 0.4430\n","Subject 3: 0.4576\n","Subject 2: 0.6829\n","Subject 15: 0.7184\n","Subject 1: 0.7379\n","Subject 4: 0.7428\n","Subject 13: 0.7589\n","Subject 7: 0.7624\n","Subject 10: 0.7666\n","Subject 5: 0.7914\n","Subject 14: 0.7931\n","Subject 9: 0.8313\n","Subject 6: 0.8484\n","Subject 11: 0.8542\n","Subject 12: 0.9131\n","\n","â­ ì „ì²´ í‰ê·  F1: 0.7401\n"]}]}]}