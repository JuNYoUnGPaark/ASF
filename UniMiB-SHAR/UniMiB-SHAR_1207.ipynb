{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP_BZVnK8ib5",
        "outputId": "5fb191a9-e983-4129-d6c6-ea072f864687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "현재 위치: /content/drive/MyDrive/Colab Notebooks/ASF/UniMiB-SHAR\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. 드라이브 연결\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. 파일이 있는 폴더로 이동 (이미지의 경로 기준)\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/ASF/UniMiB-SHAR')\n",
        "\n",
        "print(f\"현재 위치: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fvcore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-t5MQMta9lmo",
        "outputId": "b240f65c-2b8d-4ba6-b33d-40e7f335b027"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fvcore) (2.0.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from fvcore) (6.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore) (3.2.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from fvcore) (11.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from iopath>=0.1.7->fvcore) (4.15.0)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=039f49023abedea242843bf3be1fc2adbb9d038656ddd4d88f4ca40ae9a793f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=6ad9d3d38978af153c03b1c4fd9dec36d6da353484f3a5279279c55d689cccba\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/96/04/4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.2.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOQHOlKf9mdU",
        "outputId": "d220b188-cede-4767-bae8-1148472bf1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TRAIN] Loaded UniMiB-SHAR ADL: 6063 samples (Shape: (151, 3))\n",
            "[TEST] Loaded UniMiB-SHAR ADL: 1516 samples (Shape: (151, 3))\n",
            "Computed Class Weights: tensor([5.5040, 3.8987, 0.4845, 0.4242, 0.9143, 1.1288, 0.6360, 2.8450, 4.2106],\n",
            "       device='cuda:0')\n",
            "[01/50] Train Loss: 2.062 | F1: 0.3542  |  Test F1: 0.4068 (Best: 0.4068) Saved Best Model\n",
            "[02/50] Train Loss: 1.589 | F1: 0.5409  |  Test F1: 0.4624 (Best: 0.4624) Saved Best Model\n",
            "[03/50] Train Loss: 1.388 | F1: 0.6349  |  Test F1: 0.6464 (Best: 0.6464) Saved Best Model\n",
            "[04/50] Train Loss: 1.245 | F1: 0.6885  |  Test F1: 0.6605 (Best: 0.6605) Saved Best Model\n",
            "[05/50] Train Loss: 1.168 | F1: 0.7264  |  Test F1: 0.7879 (Best: 0.7879) Saved Best Model\n",
            "[06/50] Train Loss: 1.093 | F1: 0.7698  |  Test F1: 0.8019 (Best: 0.8019) Saved Best Model\n",
            "[07/50] Train Loss: 1.014 | F1: 0.8061  |  Test F1: 0.7227 (Best: 0.8019) \n",
            "[08/50] Train Loss: 0.996 | F1: 0.8127  |  Test F1: 0.7984 (Best: 0.8019) \n",
            "[09/50] Train Loss: 0.922 | F1: 0.8564  |  Test F1: 0.7654 (Best: 0.8019) \n",
            "[10/50] Train Loss: 0.890 | F1: 0.8716  |  Test F1: 0.8599 (Best: 0.8599) Saved Best Model\n",
            "[11/50] Train Loss: 0.866 | F1: 0.8741  |  Test F1: 0.8752 (Best: 0.8752) Saved Best Model\n",
            "[12/50] Train Loss: 0.838 | F1: 0.8963  |  Test F1: 0.8793 (Best: 0.8793) Saved Best Model\n",
            "[13/50] Train Loss: 0.827 | F1: 0.8868  |  Test F1: 0.8784 (Best: 0.8793) \n",
            "[14/50] Train Loss: 0.786 | F1: 0.9137  |  Test F1: 0.8353 (Best: 0.8793) \n",
            "[15/50] Train Loss: 0.775 | F1: 0.9169  |  Test F1: 0.8401 (Best: 0.8793) \n",
            "[16/50] Train Loss: 0.745 | F1: 0.9225  |  Test F1: 0.8533 (Best: 0.8793) \n",
            "[17/50] Train Loss: 0.720 | F1: 0.9389  |  Test F1: 0.8319 (Best: 0.8793) \n",
            "[18/50] Train Loss: 0.728 | F1: 0.9299  |  Test F1: 0.8405 (Best: 0.8793) \n",
            "[19/50] Train Loss: 0.717 | F1: 0.9407  |  Test F1: 0.8694 (Best: 0.8793) \n",
            "[20/50] Train Loss: 0.716 | F1: 0.9390  |  Test F1: 0.9143 (Best: 0.9143) Saved Best Model\n",
            "[21/50] Train Loss: 0.671 | F1: 0.9583  |  Test F1: 0.8580 (Best: 0.9143) \n",
            "[22/50] Train Loss: 0.658 | F1: 0.9608  |  Test F1: 0.9209 (Best: 0.9209) Saved Best Model\n",
            "[23/50] Train Loss: 0.674 | F1: 0.9519  |  Test F1: 0.9047 (Best: 0.9209) \n",
            "[24/50] Train Loss: 0.634 | F1: 0.9705  |  Test F1: 0.9428 (Best: 0.9428) Saved Best Model\n",
            "[25/50] Train Loss: 0.620 | F1: 0.9763  |  Test F1: 0.9412 (Best: 0.9428) \n",
            "[26/50] Train Loss: 0.625 | F1: 0.9763  |  Test F1: 0.9245 (Best: 0.9428) \n",
            "[27/50] Train Loss: 0.621 | F1: 0.9757  |  Test F1: 0.9353 (Best: 0.9428) \n",
            "[28/50] Train Loss: 0.612 | F1: 0.9760  |  Test F1: 0.9398 (Best: 0.9428) \n",
            "[29/50] Train Loss: 0.610 | F1: 0.9840  |  Test F1: 0.9402 (Best: 0.9428) \n",
            "[30/50] Train Loss: 0.611 | F1: 0.9771  |  Test F1: 0.9542 (Best: 0.9542) Saved Best Model\n",
            "[31/50] Train Loss: 0.593 | F1: 0.9859  |  Test F1: 0.9479 (Best: 0.9542) \n",
            "[32/50] Train Loss: 0.588 | F1: 0.9861  |  Test F1: 0.9397 (Best: 0.9542) \n",
            "[33/50] Train Loss: 0.593 | F1: 0.9864  |  Test F1: 0.9534 (Best: 0.9542) \n",
            "[34/50] Train Loss: 0.584 | F1: 0.9892  |  Test F1: 0.9598 (Best: 0.9598) Saved Best Model\n",
            "[35/50] Train Loss: 0.583 | F1: 0.9894  |  Test F1: 0.9516 (Best: 0.9598) \n",
            "[36/50] Train Loss: 0.582 | F1: 0.9891  |  Test F1: 0.9503 (Best: 0.9598) \n",
            "[37/50] Train Loss: 0.576 | F1: 0.9925  |  Test F1: 0.9422 (Best: 0.9598) \n",
            "[38/50] Train Loss: 0.589 | F1: 0.9899  |  Test F1: 0.9451 (Best: 0.9598) \n",
            "[39/50] Train Loss: 0.575 | F1: 0.9936  |  Test F1: 0.9514 (Best: 0.9598) \n",
            "[40/50] Train Loss: 0.572 | F1: 0.9943  |  Test F1: 0.9547 (Best: 0.9598) \n",
            "[41/50] Train Loss: 0.565 | F1: 0.9976  |  Test F1: 0.9540 (Best: 0.9598) \n",
            "[42/50] Train Loss: 0.573 | F1: 0.9927  |  Test F1: 0.9640 (Best: 0.9640) Saved Best Model\n",
            "[43/50] Train Loss: 0.571 | F1: 0.9936  |  Test F1: 0.9533 (Best: 0.9640) \n",
            "[44/50] Train Loss: 0.564 | F1: 0.9978  |  Test F1: 0.9543 (Best: 0.9640) \n",
            "[45/50] Train Loss: 0.571 | F1: 0.9956  |  Test F1: 0.9594 (Best: 0.9640) \n",
            "[46/50] Train Loss: 0.561 | F1: 0.9969  |  Test F1: 0.9570 (Best: 0.9640) \n",
            "[47/50] Train Loss: 0.564 | F1: 0.9957  |  Test F1: 0.9574 (Best: 0.9640) \n",
            "[48/50] Train Loss: 0.566 | F1: 0.9976  |  Test F1: 0.9593 (Best: 0.9640) \n",
            "[49/50] Train Loss: 0.566 | F1: 0.9971  |  Test F1: 0.9594 (Best: 0.9640) \n",
            "[50/50] Train Loss: 0.567 | F1: 0.9964  |  Test F1: 0.9598 (Best: 0.9640) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python visualize.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R2cy2KQ9ndS",
        "outputId": "dd00a061-1a37-4bd7-c7e3-379bcaac0d8c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Running Visualization...\n",
            "Loading weights from: /content/drive/MyDrive/Colab Notebooks/ASF/UniMiB-SHAR/UniMiB-SHAR_ASF.pth\n",
            "--------------------------------------------------------------------------------\n",
            "[TEST] Loaded UniMiB-SHAR ADL: 1516 samples (Shape: (151, 3))\n",
            "✅ Model weights loaded successfully!\n",
            "--------------------------------------------------------------------------------\n",
            "Evaluating Model Efficiency...\n",
            "1. Parameters       : 0.0954 M\n",
            "2. FLOPs / sample   : 7.866 M\n",
            "3. Infer time       : 1.66 ms/sample\n",
            "--------------------------------------------------------------------------------\n",
            "Extracting features and predictions...\n",
            "Generating Confusion Matrix...\n",
            "\n",
            "================================================================================\n",
            "Classification Report\n",
            "================================================================================\n",
            "                          precision    recall  f1-score   support\n",
            "\n",
            "Standing up from sitting     0.9565    0.8800    0.9167        25\n",
            " Standing up from laying     0.8684    0.9167    0.8919        36\n",
            "                 Walking     1.0000    0.9970    0.9985       335\n",
            "                 Running     1.0000    0.9951    0.9975       408\n",
            "          Going upstairs     1.0000    1.0000    1.0000       189\n",
            "                 Jumping     0.9938    1.0000    0.9969       161\n",
            "        Going downstairs     0.9964    1.0000    0.9982       275\n",
            "Lying down from standing     0.9556    0.8958    0.9247        48\n",
            "            Sitting down     0.9070    1.0000    0.9512        39\n",
            "\n",
            "                accuracy                         0.9908      1516\n",
            "               macro avg     0.9642    0.9650    0.9640      1516\n",
            "            weighted avg     0.9910    0.9908    0.9908      1516\n",
            "\n",
            "Figure(1800x1800)\n",
            "Generating Feature t-SNE...\n",
            "\n",
            "Running t-SNE on 1516 points (Perplexity=30)...\n",
            "Figure(800x800)\n",
            "Generating Raw Data t-SNE...\n",
            "\n",
            "Running Raw Data t-SNE on 1516 points...\n",
            "Figure(800x800)\n",
            "\n",
            "Visualization Complete!\n"
          ]
        }
      ]
    }
  ]
}
